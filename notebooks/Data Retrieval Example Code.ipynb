{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to retreive data into Python from Postgres and/or files in an S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieiving data from Postgres tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special note: Maya is awesome for figuring out that sqlalchemy piece!  :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the connection to the database\n",
    "db_loc = 'postgresql+psycopg2://postgres:pass@localhost:5432/solarenergy'\n",
    "engine = create_engine(db_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read contents of a postgres table into a dataframe\n",
    "# IMPORTANT: If you want the dataframe to add a new index,\n",
    "# remove the index_col argument out of the below code.\n",
    "# If you're unsure how this would look, just run the code below\n",
    "# with and without the index_col argument, then take a look\n",
    "# at the resulting dataframe to see the difference\n",
    "test_df = pd.read_sql('SELECT * FROM plants', engine, index_col = \"plant_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code goes at the top of any script that will be analyzing the data in any way. Note that how you set up the database with the read_sql code above will determine how you query it in this script.  The dataframe created in a single script will only persist within that script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Always take a look at the dataframe while you are building the code!\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving data from CSV files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assumption 1: the file (test.csv) is in the same folder\n",
    "# from which this command is run.  If not, just add\n",
    "# the full path to the file inside the quotes, i.e.,\n",
    "# pd.read_csv('/home/w205/whatever_name.csv', etc...\n",
    "\n",
    "# Asumption 2: that the index column in the csv is \n",
    "# named \"index\".  This, of course, won't be the same in \n",
    "# our working files.\n",
    "# The solution:  take a look at the CSV file and note\n",
    "# the column name of the first column, which is presumably\n",
    "# what should be turned into the index in the dataframe.\n",
    "# Then replace the word 'index' in the code below with \n",
    "# that column name.\n",
    "# Unless, of course, you want this dataframe to create a \n",
    "# new numerical index.  Then remove the index_col argument.\n",
    "test_df = pd.read_csv('test.csv', index_col = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As when retrieving data from a Postgres table,\n",
    "# always take a look at the data before buliding code!\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving a file from an S3 bucket via Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: writing code to programmatically copy CSV files from the AMI to S3 turned out to require some work with permissions that was beyond me (Laura). So that particular piece is not included in the project code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I manually uploaded CSV files created from the Postgres tables to my Amazon S3 account. Anyone can download those files with the following code.  \n",
    "** MAKE SURE TO ENTER IT ON THE COMMAND LINE OR ADD ! BEFORE IT IF RUNNING IT FROM A NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wget http://s3.amazonaws.com/w205.project.sunshine/csv_files/plants.csv\n",
    "wget http://s3.amazonaws.com/w205.project.sunshine/csv_files/generation.csv\n",
    "wget http://s3.amazonaws.com/w205.project.sunshine/csv_files/solar.csv\n",
    "wget http://s3.amazonaws.com/w205.project.sunshine/csv_files/uscrn.csv\n",
    "wget http://s3.amazonaws.com/w205.project.sunshine/csv_files/stations.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
